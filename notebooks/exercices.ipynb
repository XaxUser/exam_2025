{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CACBFsndOCo"
      },
      "source": [
        "# Exercices"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Préliminaires**: Clone de votre repo et imports"
      ],
      "metadata": {
        "id": "hfkMtaHleKAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/XaxUser/exam_2025.git\n",
        "! cp exam_2025/utils/utils_exercices.py .\n",
        "\n",
        "import copy\n",
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "xiD_cI-geJjI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d1a9ff-5f18-4d41-8e5e-7681c8ae43ab"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exam_2025'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/59)\u001b[K\rremote: Counting objects:   3% (2/59)\u001b[K\rremote: Counting objects:   5% (3/59)\u001b[K\rremote: Counting objects:   6% (4/59)\u001b[K\rremote: Counting objects:   8% (5/59)\u001b[K\rremote: Counting objects:  10% (6/59)\u001b[K\rremote: Counting objects:  11% (7/59)\u001b[K\rremote: Counting objects:  13% (8/59)\u001b[K\rremote: Counting objects:  15% (9/59)\u001b[K\rremote: Counting objects:  16% (10/59)\u001b[K\rremote: Counting objects:  18% (11/59)\u001b[K\rremote: Counting objects:  20% (12/59)\u001b[K\rremote: Counting objects:  22% (13/59)\u001b[K\rremote: Counting objects:  23% (14/59)\u001b[K\rremote: Counting objects:  25% (15/59)\u001b[K\rremote: Counting objects:  27% (16/59)\u001b[K\rremote: Counting objects:  28% (17/59)\u001b[K\rremote: Counting objects:  30% (18/59)\u001b[K\rremote: Counting objects:  32% (19/59)\u001b[K\rremote: Counting objects:  33% (20/59)\u001b[K\rremote: Counting objects:  35% (21/59)\u001b[K\rremote: Counting objects:  37% (22/59)\u001b[K\rremote: Counting objects:  38% (23/59)\u001b[K\rremote: Counting objects:  40% (24/59)\u001b[K\rremote: Counting objects:  42% (25/59)\u001b[K\rremote: Counting objects:  44% (26/59)\u001b[K\rremote: Counting objects:  45% (27/59)\u001b[K\rremote: Counting objects:  47% (28/59)\u001b[K\rremote: Counting objects:  49% (29/59)\u001b[K\rremote: Counting objects:  50% (30/59)\u001b[K\rremote: Counting objects:  52% (31/59)\u001b[K\rremote: Counting objects:  54% (32/59)\u001b[K\rremote: Counting objects:  55% (33/59)\u001b[K\rremote: Counting objects:  57% (34/59)\u001b[K\rremote: Counting objects:  59% (35/59)\u001b[K\rremote: Counting objects:  61% (36/59)\u001b[K\rremote: Counting objects:  62% (37/59)\u001b[K\rremote: Counting objects:  64% (38/59)\u001b[K\rremote: Counting objects:  66% (39/59)\u001b[K\rremote: Counting objects:  67% (40/59)\u001b[K\rremote: Counting objects:  69% (41/59)\u001b[K\rremote: Counting objects:  71% (42/59)\u001b[K\rremote: Counting objects:  72% (43/59)\u001b[K\rremote: Counting objects:  74% (44/59)\u001b[K\rremote: Counting objects:  76% (45/59)\u001b[K\rremote: Counting objects:  77% (46/59)\u001b[K\rremote: Counting objects:  79% (47/59)\u001b[K\rremote: Counting objects:  81% (48/59)\u001b[K\rremote: Counting objects:  83% (49/59)\u001b[K\rremote: Counting objects:  84% (50/59)\u001b[K\rremote: Counting objects:  86% (51/59)\u001b[K\rremote: Counting objects:  88% (52/59)\u001b[K\rremote: Counting objects:  89% (53/59)\u001b[K\rremote: Counting objects:  91% (54/59)\u001b[K\rremote: Counting objects:  93% (55/59)\u001b[K\rremote: Counting objects:  94% (56/59)\u001b[K\rremote: Counting objects:  96% (57/59)\u001b[K\rremote: Counting objects:  98% (58/59)\u001b[K\rremote: Counting objects: 100% (59/59)\u001b[K\rremote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 59 (delta 21), reused 20 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (59/59), 1.41 MiB | 15.01 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clef personnelle pour la partie théorique**\n",
        "\n",
        "Dans la cellule suivante, choisir un entier entre 100 et 1000 (il doit être personnel). Cet entier servira de graine au générateur de nombres aléatoire a conserver pour tous les exercices.\n",
        "\n"
      ],
      "metadata": {
        "id": "J3ga_6BNc5DR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mySeed = 200"
      ],
      "metadata": {
        "id": "PrCTHM4od5UZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "TRWBLVpCWC06"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RcggmAkJLV"
      },
      "source": [
        "\\\n",
        "\n",
        "**Exercice 1** *Une relation linéaire*\n",
        "\n",
        "La fonction *generate_dataset* fournit deux jeux de données (entraînement et test). Pour chaque jeu de données, la clef 'inputs' donne accès à un tableau numpy (numpy array) de prédicteurs empilés horizontalement : chaque ligne $i$ contient trois prédicteurs $x_i$, $y_i$ et $z_i$. La clef 'targets' renvoie le vecteur des cibles $t_i$. \\\n",
        "\n",
        "Les cibles sont liées aux prédicteurs par le modèle:\n",
        "$$ t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon$$ où $\\epsilon \\sim \\mathcal{N}(0,\\eta)$\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset, Dataset1\n",
        "train_set, test_set = generate_dataset(mySeed)"
      ],
      "metadata": {
        "id": "gEQmgTI8my8i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Par quelle méthode simple peut-on estimer les coefficients $\\theta_k$ ? La mettre en oeuvre avec la librairie python de votre choix."
      ],
      "metadata": {
        "id": "q5XZTrXNk12K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Réponse\n",
        "Pour estimer les coefficients $\\theta_k$ on peut utiliser la régression linéaire."
      ],
      "metadata": {
        "id": "TX7onAQIXJRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils_exercices import generate_dataset\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Générer les jeux de données\n",
        "train_set, test_set = generate_dataset(mySeed)\n",
        "\n",
        "# Extraction des données d'entraînement\n",
        "X_train = train_set['inputs']  # Matrice des prédicteurs\n",
        "y_train = train_set['targets']  # Vecteur des cibles\n",
        "\n",
        "# Extraction des données de test (optionnel, utilisé pour validation)\n",
        "X_test = test_set['inputs']\n",
        "y_test = test_set['targets']\n",
        "\n",
        "# Initialiser et ajuster le modèle de régression linéaire\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Récupérer les coefficients et l'ordonnée à l'origine\n",
        "theta_0 = model.intercept_  # Ordonnée à l'origine\n",
        "coefficients = model.coef_  # Coefficients associés aux prédicteurs\n",
        "\n",
        "# Affichage des résultats\n",
        "print(\"Résultats de la régression linéaire :\")\n",
        "print(f\"Ordonnée à l'origine (theta_0): {theta_0}\")\n",
        "print(f\"Coefficients des prédicteurs (theta_1, theta_2, theta_3): {coefficients}\")\n"
      ],
      "metadata": {
        "id": "HITtUqHhFMkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce9fcefd-f9d6-4cc6-9c01-b066068e019f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Résultats de la régression linéaire :\n",
            "Ordonnée à l'origine (theta_0): 10.078764034363882\n",
            "Coefficients des prédicteurs (theta_1, theta_2, theta_3): [1.95156862 1.94842221 3.59966699]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans les cellules suivantes, on se propose d'estimer les $\\theta_k$ grâce à un réseau de neurones entraîné par SGD. Quelle architecture s'y prête ? Justifier en termes d'expressivité et de performances en généralisation puis la coder dans la cellule suivante."
      ],
      "metadata": {
        "id": "CH_Z5ZEIlQPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Réponse\n",
        "Pour estimer les $\\theta_k$ à l’aide d’un réseau de neurones entraîné par SGD, l’architecture la plus adaptée est un réseau de neurones simple (simple perceptron) avec :\n",
        "- Un seul neurone en sortie : Pour produire une prédiction $t$, en tant que combinaison linéaire des entrées $x$, $y$, $z$.\n",
        "\n",
        "- Pas de couche cachée : Une seule couche linéaire suffit, car le problème est linéaire (donnée par la relation suivante) :\n",
        "$\n",
        "t = \\theta_0 + \\theta_1 x + \\theta_2 y + \\theta_3 z + \\epsilon.\n",
        "$\n",
        "\n",
        "- Fonction d’activation linéaire : Aucune activation n’est nécessaire pour un problème purement linéaire."
      ],
      "metadata": {
        "id": "vEC6ZtTIYlvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Justification:\n",
        "- Expressivité : Un réseau à une seule couche (sans activation non-linéaire) est suffisant pour apprendre une relation linéaire. Ajouter des couches cachées serait inutile et pourrait ralentir l'entraînement.\n",
        "- Performance en généralisation : Ce modèle simple a peu de paramètres et évite le surapprentissage. Il est donc efficace pour généraliser à des données non vues."
      ],
      "metadata": {
        "id": "N72nv9FfaRcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# Dataset et dataloader :\n",
        "dataset = Dataset1(train_set['inputs'], train_set['targets'])\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=True)\n",
        "\n",
        "# A coder :\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        # Couche linéaire pour apprendre les coefficients\n",
        "        self.linear = nn.Linear(3, 1)  # 3 entrées (x, y, z), 1 sortie (t)\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)  # Pas d'activation pour garder la linéarité"
      ],
      "metadata": {
        "id": "PPx543blnxdb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Entraîner cette architecture à la tâche de régression définie par les entrées et sorties du jeu d'entraînement (compléter la cellule ci-dessous)."
      ],
      "metadata": {
        "id": "g6BSTBitpGBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss, and optimizer\n",
        "mySimpleNet = SimpleNet()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(mySimpleNet.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 500\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0.0  # Pour suivre la perte moyenne de l'époque\n",
        "    for batch_inputs, batch_targets in dataloader:\n",
        "        # Étape 1 : Passer les entrées dans le modèle\n",
        "        predictions = mySimpleNet(batch_inputs).squeeze()  # Sorties du modèle\n",
        "\n",
        "        # Étape 2 : Calculer la perte\n",
        "        loss = criterion(predictions, batch_targets)\n",
        "\n",
        "        # Étape 3 : Backpropagation\n",
        "        optimizer.zero_grad()  # Réinitialiser les gradients\n",
        "        loss.backward()  # Calculer les gradients\n",
        "        optimizer.step()  # Mettre à jour les poids\n",
        "\n",
        "        # Accumuler la perte pour l'époque\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Afficher la perte moyenne toutes les 50 époques\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss / len(dataloader):.4f}\")\n",
        "\n",
        "# Extraction des coefficients appris après entraînement\n",
        "theta_0 = mySimpleNet.linear.bias.item()  # Ordonnée à l'origine\n",
        "theta_1, theta_2, theta_3 = mySimpleNet.linear.weight.squeeze().tolist()  # Coefficients\n",
        "\n",
        "print(\"\\nRésultats après entraînement :\")\n",
        "print(f\"Coefficients (theta _0, theta_1, theta_2, theta_3): {theta_0},{theta_1}, {theta_2}, {theta_3}\")"
      ],
      "metadata": {
        "id": "Wjfa2Z4RoPO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27645f5b-3a13-4bb5-9e7e-3e8941f79e40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500, Loss: 3.8516\n",
            "Epoch 100/500, Loss: 3.8374\n",
            "Epoch 150/500, Loss: 3.8368\n",
            "Epoch 200/500, Loss: 3.8372\n",
            "Epoch 250/500, Loss: 3.8376\n",
            "Epoch 300/500, Loss: 3.8380\n",
            "Epoch 350/500, Loss: 3.8383\n",
            "Epoch 400/500, Loss: 3.8377\n",
            "Epoch 450/500, Loss: 3.8375\n",
            "Epoch 500/500, Loss: 3.8371\n",
            "\n",
            "Résultats après entraînement :\n",
            "Coefficients (theta _0, theta_1, theta_2, theta_3): 10.08033561706543,1.9527450799942017, 1.9474800825119019, 3.600365400314331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Où sont alors stockées les estimations des  $\\theta_k$ ? Les extraire du réseau *mySimpleNet* dans la cellule suivante."
      ],
      "metadata": {
        "id": "OZwKogEEp2Fr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans le réseau mySimpleNet, les estimations des $\\theta_k$ sont stockées dans les paramètres de la couche linéaire"
      ],
      "metadata": {
        "id": "N5nTYM8LdgTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des paramètres de la couche linéaire\n",
        "theta_0 = mySimpleNet.linear.bias.item()  # Ordonnée à l'origine (bias)\n",
        "theta_1, theta_2, theta_3 = mySimpleNet.linear.weight.squeeze().tolist()  # Coefficients\n",
        "\n",
        "# Affichage des résultats\n",
        "print(\"Estimations des coefficients (θ_k) :\")\n",
        "print(f\"Ordonnée à l'origine (θ₀) : {theta_0}\")\n",
        "print(f\"Coefficient de x (θ₁) : {theta_1}\")\n",
        "print(f\"Coefficient de y (θ₂) : {theta_2}\")\n",
        "print(f\"Coefficient de z (θ₃) : {theta_3}\")\n"
      ],
      "metadata": {
        "id": "EjgWp1y1rseb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc76d40-16a4-4e73-c6af-001213bdfbae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimations des coefficients (θ_k) :\n",
            "Ordonnée à l'origine (θ₀) : 10.08033561706543\n",
            "Coefficient de x (θ₁) : 1.9527450799942017\n",
            "Coefficient de y (θ₂) : 1.9474800825119019\n",
            "Coefficient de z (θ₃) : 3.600365400314331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Tester ces estimations sur le jeu de test et comparer avec celles de la question 1. Commentez."
      ],
      "metadata": {
        "id": "pEB-V-oOrJED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jeu de test\n",
        "test_inputs = torch.tensor(test_set['inputs'], dtype=torch.float32)\n",
        "test_targets = torch.tensor(test_set['targets'], dtype=torch.float32)\n",
        "\n",
        "# Prédictions du réseau neuronal\n",
        "test_predictions_nn = mySimpleNet(test_inputs).squeeze()\n",
        "\n",
        "# Calcul de la perte sur le jeu de test (réseau neuronal)\n",
        "test_loss_nn = criterion(test_predictions_nn, test_targets)\n",
        "print(f\"Perte sur le jeu de test (réseau neuronal) : {test_loss_nn.item():.4f}\")\n",
        "\n",
        "# Comparaison avec les estimations de la régression linéaire classique\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Prédictions du modèle de régression linéaire (Question 1)\n",
        "test_predictions_lr = model.predict(test_set['inputs'])\n",
        "\n",
        "# Calcul de la perte pour la régression linéaire\n",
        "test_loss_lr = mean_squared_error(test_set['targets'], test_predictions_lr)\n",
        "print(f\"Perte sur le jeu de test (régression linéaire) : {test_loss_lr:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txXLodOIeXe1",
        "outputId": "c41c7f5e-2640-4ecf-a495-cd96f5fbb789"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perte sur le jeu de test (réseau neuronal) : 4.0087\n",
            "Perte sur le jeu de test (régression linéaire) : 4.0093\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau de neuronne et la régression linéaire on appris des modèle similaire. Par contre la régression linéaire classique converge directement vers la solution théorique. Tandis que le réseau de neuronne dépend de la méthode utiliser pour optimiser la fonction loss. Ici la descente de gradient stochastique.\n",
        "\n",
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "VvV2jIrBNtzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercice 2** *Champ réceptif et prédiction causale*"
      ],
      "metadata": {
        "id": "CpRvXCaAtsIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini dans la cellule suivante est utilisé pour faire le lien entre les valeurs $(x_{t' \\leq t})$ d'une série temporelle d'entrée et la valeur présente $y_t$ d'une série temporelle cible."
      ],
      "metadata": {
        "id": "8JG9wTfK5TBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from utils_exercices import Outconv, Up_causal, Down_causal\n",
        "\n",
        "class Double_conv_causal(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2, with causal convolutions that preserve input size'''\n",
        "    def __init__(self, in_ch, out_ch, kernel_size=3, dilation=1):\n",
        "        super(Double_conv_causal, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.conv1 = nn.Conv1d(in_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn1 = nn.BatchNorm1d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv1d(out_ch, out_ch, kernel_size=kernel_size, padding=0, dilation=dilation)\n",
        "        self.bn2 = nn.BatchNorm1d(out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = F.pad(x, ((self.kernel_size - 1) * self.dilation, 0))\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class causalFCN(nn.Module):\n",
        "    def __init__(self, dilation=1):\n",
        "        super(causalFCN, self).__init__()\n",
        "        size = 64\n",
        "        n_channels = 1\n",
        "        n_classes = 1\n",
        "        self.inc = Double_conv_causal(n_channels, size)\n",
        "        self.down1 = Down_causal(size, 2*size)\n",
        "        self.down2 = Down_causal(2*size, 4*size)\n",
        "        self.down3 = Down_causal(4*size, 8*size, pooling_kernel_size=5, pooling_stride=5)\n",
        "        self.down4 = Down_causal(8*size, 4*size, pooling=False, dilation=2)\n",
        "        self.up2 = Up_causal(4*size, 2*size, kernel_size=5, stride=5)\n",
        "        self.up3 = Up_causal(2*size, size)\n",
        "        self.up4 = Up_causal(size, size)\n",
        "        self.outc = Outconv(size, n_classes)\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up2(x5, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.outc(x)\n",
        "        return x\n",
        "\n",
        "# Exemple d'utilisation\n",
        "model = causalFCN()\n",
        "# Série temporelle d'entrée (x_t):\n",
        "input_tensor1 = torch.rand(1, 1, 10000)\n",
        "# Série temporelle en sortie f(x_t):\n",
        "output = model(input_tensor1)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "fIbU1EJT1MM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b9d351-cf1a-4227-d89f-9e24370e6577"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 10000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** De quel type de réseau de neurones s'agit-il ? Combien de paramètres la couche self.Down1 compte-t-elle (à faire à la main) ?\n",
        "Combien de paramètres le réseau entier compte-t-il (avec un peu de code) ?"
      ],
      "metadata": {
        "id": "-mNnsYU-7R7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le réseau défini est un **Fully Convolutional Network (FCN)** causal pour séries temporelles. Voici ses principales caractéristiques :"
      ],
      "metadata": {
        "id": "99cQSge8gywX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nb de paramètres dans self.Down1:\n",
        "Paramètres = $(3 \\times 64 \\times 128) + 128 + 128 \\times 2 = 24,960.$\n",
        "     "
      ],
      "metadata": {
        "id": "zkP3-w2hhd-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nb de paramètres au total:"
      ],
      "metadata": {
        "id": "Du8RNoyaiIXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcul du nombre total de paramètres\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Nombre total de paramètres dans le réseau : {total_params}\")"
      ],
      "metadata": {
        "id": "c50Z9c8jiVfk",
        "outputId": "572eb249-7b5e-4ea3-d20d-7641ab98f703",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de paramètres dans le réseau : 2872641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Par quels mécanismes la taille du vecteur d'entrée est-elle réduite ? Comment est-elle restituée dans la deuxième partie du réseau ?"
      ],
      "metadata": {
        "id": "I4D46A0-8LaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Réponse\n",
        "\n",
        "- **Réduction** : La taille du vecteur d'entrée est réduite dans la première partie du réseau par convolution avec stride et pooling.\n",
        "- **Restitution** : La taille est restituée dans la deuxième partie du réseau par des convolutions transposées et des concaténations avec les couches d'encodeur pour \"restaurer\" progressivement la taille de l'entrée."
      ],
      "metadata": {
        "id": "jwhtFZwIiyC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Par quels mécanismes le champ réceptif est-il augmenté ? Préciser par un calcul la taille du champ réceptif en sortie de *self.inc*."
      ],
      "metadata": {
        "id": "SVNeFnm88yV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Réponse\n",
        "\n",
        "1. **Dilatation des convolutions** :  \n",
        "   La dilatation dans les convolutions (utilisée notamment dans les couches `Down_causal` et `Up_causal`) permet d'augmenter le champ réceptif sans ajouter de paramètres supplémentaires ni augmenter la taille du filtre.\n",
        "2. **Couches de convolution successives** :  \n",
        "   En empilant plusieurs couches de convolutions, le champ réceptif augmente de manière cumulative. Chaque couche successive permet à chaque neurone de capturer des informations de plus en plus larges sur l'entrée.  \n",
        "   - Par exemple, si une couche avec un noyau de taille 3 (et un padding causal) capture une \"fenêtre\" de 3 valeurs d'entrée, une deuxième couche appliquée immédiatement après permettra à chaque neurone de voir une fenêtre de 5 valeurs d'entrée (3+3-1).\n",
        "\n",
        "3. **Pooling et stride** :  \n",
        "   Dans les couches de réduction (`Down_causal`), l'utilisation du pooling et des strides augmente également indirectement le champ réceptif. Bien que le pooling réduise la taille de l'entrée, il permet de capturer des informations sur des sous-échelles plus globales, ce qui augmente le champ réceptif global.\n",
        "\n",
        "\n",
        "   La première couche `self.inc` est composée de deux convolutions successives dans la classe `Double_conv_causal` :\n",
        "- Chaque convolution a un **kernel size** de 3.\n",
        "- La **dilatation** est de 1 pour les convolutions dans `self.inc`.\n",
        "\n",
        "**Calcul de la taille du champ réceptif** après chaque couche :\n",
        "\n",
        "1. **Première convolution (`conv1`)** :  \n",
        "   - Taille du filtre : 3  \n",
        "   - Dilatation : 1 (pas de saut dans les positions d'entrée)  \n",
        "   - Padding causal : 2 (le padding est appliqué sur le côté gauche de l'entrée pour maintenir la taille de la sortie identique à l'entrée)  \n",
        "   - Le champ réceptif augmente de **3 - 1 = 2** pour chaque position de sortie (puisque le padding causal compense l'effet du bord).\n",
        "\n",
        "2. **Deuxième convolution (`conv2`)** :  \n",
        "   - Taille du filtre : 3  \n",
        "   - Dilatation : 1  \n",
        "   - Le champ réceptif est à nouveau augmenté de 2, car il s'étend d'une fenêtre de 3 valeurs supplémentaires.\n",
        "\n",
        "**Total du champ réceptif en sortie de `self.inc`** :  \n",
        "Le champ réceptif total après les deux convolutions successives est de :\n",
        "\n",
        "Champ réceptif total $= 3 + 2 = 5$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "11rxRjbNjhzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Par un bout de code, déterminer empiriquement la taille du champ réceptif associé à la composante $y_{5000}$ du vecteur de sortie. (Indice: considérer les sorties associées à deux inputs qui ne diffèrent que par une composante...)"
      ],
      "metadata": {
        "id": "TVVcBPuA9EP0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69WMWCSZAg5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** $y_{5000}$ dépend-elle des composantes $x_{t, \\space t > 5000}$ ? Justifier de manière empirique puis préciser la partie du code de Double_conv_causal qui garantit cette propriété de \"causalité\" en justifiant.  \n",
        "\n"
      ],
      "metadata": {
        "id": "gZ37skwm-Vpv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PeooRYE-ATGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "---\n",
        "\n",
        "\\"
      ],
      "metadata": {
        "id": "qV52tusgNn6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\\n",
        "\n",
        "Exercice 3: \"Ranknet loss\""
      ],
      "metadata": {
        "id": "bm-sRzmfqc2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un [article récent](https://https://arxiv.org/abs/2403.14144) revient sur les progrès en matière de learning to rank. En voilà un extrait :"
      ],
      "metadata": {
        "id": "Wl8wUjsSM57D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nanopiero/exam_2025/refs/heads/main/utils/png_exercice3.PNG?token=GHSAT0AAAAAAC427DACOPGNDNN6UDOLVLLAZ4BB2JQ\" alt=\"extrait d'un article\" width=\"800\">"
      ],
      "metadata": {
        "id": "SDZUXMlSDpoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Qu'est-ce que les auteurs appellent \"positive samples\" et \"negative samples\" ? Donner un exemple."
      ],
      "metadata": {
        "id": "9NzV1PbMNyuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Dans l'expression de $\\mathcal{L}_{RankNet}$, d'où proviennent les $z_i$ ? Que représentent-ils ?  "
      ],
      "metadata": {
        "id": "yIKQ5Eo9OnPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Pourquoi cette expression conduit-elle à ce que, après apprentissage, \"the estimated\n",
        "value of positive samples is greater than that of negative samples\n",
        "for each pair of positive/negative samples\" ?"
      ],
      "metadata": {
        "id": "r74fWiyvPb7Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Dans le cadre d'une approche par deep learning, quels termes utilise-t-on pour qualifier les réseaux de neurones exploités et la modalité suivant laquelle ils sont entraînés ?"
      ],
      "metadata": {
        "id": "pk1EIi_VVi3R"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}